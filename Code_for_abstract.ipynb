{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageEnhance, ImageChops, ImageStat, ImageDraw\n",
    "import pandas as pd\n",
    "import glob\n",
    "import face_recognition\n",
    "import fitz\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import openpyxl\n",
    "from itertools import chain\n",
    "\n",
    "import os\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import decode_predictions, preprocess_input\n",
    "from keras.models import Model\n",
    "from tensorflow.keras import applications\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import save_model\n",
    "import tensorflow.keras.layers as L\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import tqdm\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка и загрузка файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-03-22T08:20:51.495195Z",
     "iopub.status.busy": "2023-03-22T08:20:51.494777Z",
     "iopub.status.idle": "2023-03-22T08:20:51.505267Z",
     "shell.execute_reply": "2023-03-22T08:20:51.504298Z",
     "shell.execute_reply.started": "2023-03-22T08:20:51.495106Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (939149366.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_60/939149366.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    path =\"/Users/Desktop/Python/Passports\" (здесь Ваш путь до pdf-сканов документов)\u001b[0m\n\u001b[0m                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "path =\"/Users/Desktop/Python/Passports\" (здесь Ваш путь до pdf-сканов документов) \n",
    "gPDF=glob.glob('path/*.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка пути до всех pdf-файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gPDF=glob.glob('pdf/*.pdf')\n",
    "len(gPDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция преобразования каждой страницы pdf-файла в изображение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_images_from_pdf(pdf):\n",
    "    count = 0\n",
    "    for tpdf in pdf:\n",
    "        name = Path(tpdf).stem\n",
    "        doc=fitz.open(tpdf)\n",
    "        for i in range(len(doc)):\n",
    "            for img in doc.get_page_images(i):\n",
    "                xref=img[0]\n",
    "                pix = fitz.Pixmap(doc,xref)\n",
    "                if pix.n < 5:\n",
    "                    pix.save(f'image_from_pdf/{name}p%s-%s.png' % (i,xref))\n",
    "                else:\n",
    "                    pix1 = fitz.Pixmap(fitz.csRGB, pix)\n",
    "                    pix1.save(f'image_from_pdf/{name}p%s-%s.png' % (i,xref))\n",
    "                    pix1 = None\n",
    "                pix = None\n",
    "                count+=1\n",
    "    return f'Found {count} images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Применение функции\n",
    "extract_images_from_pdf(gPDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Получаем путь до всех изображений полученных из pdf-файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g=glob.glob('image_from_pdf/*.png')\n",
    "#g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция для распознавания лица на изображении"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def face_recog_pdf(gimage):\n",
    "    count = 0\n",
    "    for timage in gimage:\n",
    "        name = Path(timage).stem\n",
    "        img = face_recognition.load_image_file(timage)\n",
    "        test_loc = face_recognition.face_locations(img)\n",
    "        for f in test_loc:\n",
    "            top, right,bottom, left = f\n",
    "            face_img = img[top:bottom,left:right]\n",
    "            pil_img = Image.fromarray(face_img)\n",
    "            pil_img.save(f'pdf_img/{name}_face_{count}.png')\n",
    "            count+=1\n",
    "    return f'Found {count} face(s) in this photos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Применение функции\n",
    "face_recog_pdf(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Архивирование изображений с лицами - если нужно\n",
    "shutil.make_archive('/home/datalab/пока_не_кейсы', 'zip', '/home/datalab/pdf_img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Получаем путь до всех изображений с распознанными лицами\n",
    "photo = glob.glob('pdf_img/*.png')\n",
    "#photo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Автоэнкодеры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Применение функции для преобразования изображений в вектора для метода автоэнкодирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image2array(filelist – путь до папки с фотографиями):\n",
    "    image_array = []\n",
    "    for image in filelist[:200]:\n",
    "        img = io.imread(image)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (224,224))\n",
    "        image_array.append(img)\n",
    "    image_array = np.array(image_array)\n",
    "    image_array = image_array.reshape(image_array.shape[0], 224, 224, 3)\n",
    "    image_array = image_array.astype('float32')\n",
    "    image_array /= 255\n",
    "    return np.array(image_array)\n",
    "\n",
    "train_data = image2array(filelist)\n",
    "print(\"Length of training dataset:\", train_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Применение функции для построения автоэнкодера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = x.shape[1:]\n",
    "def build_deep_autoencoder(img_shape, code_size):\n",
    "    H,W,C = img_shape\n",
    "    # encoder\n",
    "    encoder = tf.keras.models.Sequential() # инициализация модели\n",
    "    encoder.add(L.InputLayer(img_shape)) # добавление входного слоя, размер равен размеру изображения\n",
    "    encoder.add(L.Conv2D(filters=32, kernel_size=(3, 3), activation='elu', padding='same'))\n",
    "    encoder.add(L.MaxPooling2D(pool_size=(2, 2)))\n",
    "    encoder.add(L.Conv2D(filters=64, kernel_size=(3, 3), activation='elu', padding='same'))\n",
    "    encoder.add(L.MaxPooling2D(pool_size=(2, 2)))\n",
    "    encoder.add(L.Conv2D(filters=128, kernel_size=(3, 3), activation='elu', padding='same'))\n",
    "    encoder.add(L.MaxPooling2D(pool_size=(2, 2)))\n",
    "    encoder.add(L.Conv2D(filters=256, kernel_size=(3, 3), activation='elu', padding='same'))\n",
    "    encoder.add(L.MaxPooling2D(pool_size=(2, 2)))\n",
    "    encoder.add(L.Flatten())\n",
    "    encoder.add(L.Dense(code_size))\n",
    "\n",
    "    # decoder\n",
    "    decoder = tf.keras.models.Sequential()\n",
    "    decoder.add(L.InputLayer((code_size,)))\n",
    "    decoder.add(L.Dense(14*14*256))\n",
    "    decoder.add(L.Reshape((14, 14, 256)))\n",
    "    decoder.add(L.Conv2DTranspose(filters=128, kernel_size=(3, 3), strides=2, activation='elu', padding='same'))\n",
    "    decoder.add(L.Conv2DTranspose(filters=64, kernel_size=(3, 3), strides=2, activation='elu', padding='same'))\n",
    "    decoder.add(L.Conv2DTranspose(filters=32, kernel_size=(3, 3), strides=2, activation='elu', padding='same'))\n",
    "    decoder.add(L.Conv2DTranspose(filters=3, kernel_size=(3, 3), strides=2, activation=None, padding='same'))\n",
    "    \n",
    "    return encoder, decoder\n",
    "\n",
    "\n",
    "encoder, decoder = build_deep_autoencoder(IMG_SHAPE, code_size=32)\n",
    "encoder.summary()\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Параметры и обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = L.Input(IMG_SHAPE)\n",
    "code = encoder(inp)\n",
    "reconstruction = decoder(code)\n",
    "\n",
    "autoencoder = tf.keras.models.Model(inputs=inp, outputs=reconstruction)\n",
    "autoencoder.compile(optimizer=\"adamax\", loss='mse')\n",
    "autoencoder.fit(x=train_data, y=train_data, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = train_data\n",
    "codes = encoder.predict(images) \n",
    "assert len(codes) == len(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение модели подобия изображений при помощи K ближайших соседей (NearestNeighbours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "nei_clf = NearestNeighbors(metric=\"euclidean\")\n",
    "nei_clf.fit(codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Применение функций для вывода похожих изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar(image, n_neighbors=5):\n",
    "    assert image.ndim==3,\"image must be [batch,height,width,3]\"\n",
    "    code = encoder.predict(image[None])    \n",
    "    (distances,),(idx,) = nei_clf.kneighbors(code,n_neighbors=n_neighbors)\n",
    "    return distances,images[idx]\n",
    "def show_similar(image):\n",
    "    distances,neighbors = get_similar(image,n_neighbors=3)\n",
    "    plt.figure(figsize=[8,7])\n",
    "    plt.subplot(1,4,1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(\"Original image\")\n",
    "    \n",
    "    for i in range(3):\n",
    "        plt.subplot(1,4,i+2)\n",
    "        plt.imshow(neighbors[i])\n",
    "        plt.title(\"Dist=%.3f\"%distances[i])\n",
    "   \t    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Использование предобученных моделей для извлечения признаков из изображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка весов модели\n",
    "model = keras.applications.vgg16.VGG16(weights='imagenet', include_top=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    img = image.load_img(path, target_size=model.input_shape[1:3])\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return img, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Использование модели\n",
    "feat_extractor = Model(inputs=model.input, outputs=model.get_layer(\"fc2\").output)\n",
    "feat_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "tic = time.perf_counter()\n",
    "features = []\n",
    "for i, image_path in enumerate(filelist[:200]):\n",
    "    if i % 500 == 0:\n",
    "        toc = time.perf_counter()\n",
    "        elap = toc-tic;\n",
    "        print(\"analyzing image %d / %d. Time: %4.4f seconds.\" % (i, len(images),elap))\n",
    "        tic = time.perf_counter()\n",
    "    img, x = load_image(path);\n",
    "    feat = feat_extractor.predict(x)[0]\n",
    "    features.append(feat)\n",
    "print('finished extracting features for %d images' % len(images))\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "features = np.array(features)\n",
    "pca = PCA(n_components=100)\n",
    "pca.fit(features)\n",
    "\n",
    "pca_features = pca.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Поиск похожих изображений\n",
    "from scipy.spatial import distance\n",
    "similar_idx = [ distance.cosine(pca_features[80], feat) for feat in pca_features ]\n",
    "\n",
    "idx_closest = sorted(range(len(similar_idx)), key=lambda k: similar_idx[k])[1:6] # отображение первых 6 похожих изображений\n",
    "\n",
    "thumbs = []\n",
    "for idx in idx_closest:\n",
    "    img = image.load_img(filelist[idx])\n",
    "    img = img.resize((int(img.width * 100 / img.height), 100))\n",
    "    thumbs.append(img)\n",
    "\n",
    "# concatenate the images into a single image\n",
    "concat_image = np.concatenate([np.asarray(t) for t in thumbs], axis=1)\n",
    "\n",
    "# show the image\n",
    "plt.figure(figsize = (16,12))\n",
    "plt.imshow(concat_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Использование готовых библиотек"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция для перевода изображений в вектор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# На выходе выдает словарь с векторами изображений и список \"плохих изображений\", для которых вектор не определился\n",
    "def get_vector(train_image):\n",
    "    diff = {}\n",
    "    bad = []\n",
    "    for image in tqdm(train_image):\n",
    "        try:\n",
    "            img = face_recognition.load_image_file(image)\n",
    "            img_enc = face_recognition.face_encodings(img)[0]\n",
    "            diff.update({image:img_enc})\n",
    "        except IndexError:\n",
    "            bad.append(image)\n",
    "    return diff, bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применение функции\n",
    "r, bf = get_vector(photo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция для кодирования изображения в вектор и сравнения каждого изображения со всем набором изображений в датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_faces(test_image, train_images):\n",
    "    img1 = face_recognition.load_image_file(test_image)\n",
    "    img1_enc = face_recognition.face_encodings(img1)[0]\n",
    "    print('Original_image:')\n",
    "    print(Path(test_image).stem)\n",
    "    Image.fromarray(img1).show()\n",
    "    print('Compared images:')\n",
    "    differences = {}\n",
    "    for name,vec in tqdm(train_images.items()):\n",
    "        try:\n",
    "            result = face_recognition.compare_faces([img1_enc], vec, tolerance=0.49)\n",
    "            differences.update({name:result})\n",
    "        except IndexError:\n",
    "            pass            \n",
    "    new_df = {key:value for key,value in differences.items() if value == [True]}\n",
    "    fig = plt.figure(figsize=(15,len(new_df.keys())))\n",
    "    rows,cols = 1, len(new_df.keys())\n",
    "    for idx, i in enumerate(new_df.keys()):\n",
    "        #if Path(i).stem[:20] != Path(i+1).stem[:20]:\n",
    "        fig.add_subplot(rows, cols, idx+1)\n",
    "        im = Image.open(i)\n",
    "        print(Path(i).stem)\n",
    "        plt.imshow(im)\n",
    "        plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применение функции\n",
    "compare_faces(photo[9], r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T08:32:07.885323Z",
     "iopub.status.busy": "2023-03-22T08:32:07.884976Z",
     "iopub.status.idle": "2023-03-22T08:32:07.889286Z",
     "shell.execute_reply": "2023-03-22T08:32:07.888528Z",
     "shell.execute_reply.started": "2023-03-22T08:32:07.885288Z"
    },
    "tags": []
   },
   "source": [
    "### Сохранение похожих изображений в Excel-файл"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция для отображения похожих изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_images(test_image, train_image):\n",
    "    names = {}\n",
    "    for t in tqdm(test_image):\n",
    "        differences = {}\n",
    "        try:\n",
    "            img1 = face_recognition.load_image_file(t)\n",
    "            img1_enc = face_recognition.face_encodings(img1)[0]\n",
    "        except IndexError:\n",
    "            print(t)\n",
    "        for name, vector in train_image.items():\n",
    "            try:\n",
    "                result = face_recognition.compare_faces([img1_enc], vector, tolerance=0.4)\n",
    "                differences.update({name:result})\n",
    "            except IndexError:\n",
    "                pass\n",
    "        new_df = {key:value for key,value in differences.items() if value == [True]}\n",
    "        names.update({t:list(new_df.keys())})\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Применение функции\n",
    "dictionary = get_true_images(photo, r)\n",
    "#dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функция для составления датасета из набора похожих изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_names(dictionary):\n",
    "    new_list = {}\n",
    "    for idx, i in enumerate(list(dictionary.keys())):\n",
    "        b = Path(i).stem\n",
    "        stem = []\n",
    "        for j in list(dictionary.values())[idx]:\n",
    "            a = Path(j).stem\n",
    "            stem.append(a)\n",
    "        new_list.update({b:stem})\n",
    "    data = pd.DataFrame(dict([(k,pd.Series(v)) for k,v in new_list.items()]))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Применение функции\n",
    "d = get_names(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Сохранение файла в EXCEL - при необходимости. На данном этапе данные с дублями\n",
    "d.to_excel('find_faces.xlsx', sheet_name = 'Test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
